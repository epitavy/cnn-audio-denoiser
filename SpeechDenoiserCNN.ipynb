{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VoyZ5yLRaAeI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ah7ISzvtEmur"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "import soundfile\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = datetime.datetime.now().strftime(\"%m%d\")\n",
    "logc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WBZyUMpobR-Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10932094889438795789,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 2789408768\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14300969345595662734\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zu2lgR8lEmu0"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d43UvhEqxrkJ"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = \"./records/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "W36WF4mT1kGK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file names:  ['./records/train_0.tfrecords']\n",
      "Validation file names:  ['./records/val_0.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "# get training and validation tf record file names\n",
    "train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n",
    "val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n",
    "\n",
    "# suffle the file names for training\n",
    "np.random.shuffle(train_tfrecords_filenames)\n",
    "print(\"Training file names: \", train_tfrecords_filenames)\n",
    "print(\"Validation file names: \", val_tfrecords_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jKZtPoLMEmvJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windowLength: 256\n",
      "overlap: 64\n",
      "ffTLength: 256\n",
      "inputFs: 48000.0\n",
      "fs: 16000.0\n",
      "numFeatures: 129\n",
      "numSegments: 8\n"
     ]
    }
   ],
   "source": [
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "ffTLength    = windowLength\n",
    "inputFs      = 48e3\n",
    "fs           = 16e3\n",
    "numFeatures  = ffTLength//2 + 1\n",
    "numSegments  = 8\n",
    "print(\"windowLength:\",windowLength)\n",
    "print(\"overlap:\",overlap)\n",
    "print(\"ffTLength:\",ffTLength)\n",
    "print(\"inputFs:\",inputFs)\n",
    "print(\"fs:\",fs)\n",
    "print(\"numFeatures:\",numFeatures)\n",
    "print(\"numSegments:\",numSegments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzbdfIi-Lgk9"
   },
   "source": [
    "## Prepare Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "24kph3wJ3s5V"
   },
   "outputs": [],
   "source": [
    "def tf_record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n",
    "    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n",
    "    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n",
    "\n",
    "    # reshape input and annotation images\n",
    "    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n",
    "    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n",
    "    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n",
    "\n",
    "    return noise_stft_mag_features, clean_stft_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJXPGrgVTCbZ"
   },
   "source": [
    "## Create tf.Data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FF_A3YbZTCsj"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n",
    "train_dataset = train_dataset.map(tf_record_parser)\n",
    "train_dataset = train_dataset.shuffle(8192)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(512)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NOuWPzQaTNDy"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n",
    "test_dataset = test_dataset.map(tf_record_parser)\n",
    "test_dataset = test_dataset.repeat(1)\n",
    "test_dataset = test_dataset.batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEG5JofLSfRw"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2OZFegXrSYle"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lc2K0cfhPU5-"
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XFYyKoAVQYCz"
   },
   "outputs": [],
   "source": [
    "def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "    shortcut = x\n",
    "    in_channels = x.shape[-1]\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "    return shortcut + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NlRQ3ngpZG1Y"
   },
   "outputs": [],
   "source": [
    "def build_model(l2_strength):\n",
    "    inputs = Input(shape=[numFeatures,numSegments,1])\n",
    "    x = inputs\n",
    "\n",
    "    # -----\n",
    "    x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "    x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(skip0)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # -----\n",
    "    x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(skip1)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = x + skip1\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = x + skip0\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ----\n",
    "    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "    x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "    #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mNpHS4LuShxd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 129, 8, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 137, 8, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 129, 1, 18)   1296        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 129, 1, 18)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 129, 1, 18)   72          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 129, 1, 30)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 129, 1, 30)   120         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 129, 1, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 129, 1, 8)    32          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 129, 1, 18)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 129, 1, 18)   72          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 129, 1, 30)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 129, 1, 30)   120         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 129, 1, 8)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 129, 1, 8)    32          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 129, 1, 18)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 129, 1, 18)   72          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 129, 1, 30)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 129, 1, 30)   120         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 129, 1, 8)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 129, 1, 8)    32          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 129, 1, 18)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 129, 1, 18)   72          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 129, 1, 30)   0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 129, 1, 30)   0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 129, 1, 30)   120         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 129, 1, 8)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 129, 1, 8)    32          activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 129, 1, 18)   1296        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 129, 1, 18)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 129, 1, 18)   72          activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 129, 1, 30)   0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 129, 1, 30)   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 129, 1, 30)   120         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 129, 1, 8)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 129, 1, 8)    32          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 129, 1, 8)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 129, 1, 1)    1033        spatial_dropout2d[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 32,933\n",
      "Trainable params: 32,373\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(l2_strength=0.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rWOgsdwglFE"
   },
   "outputs": [],
   "source": [
    "# You might need to install the following dependencies: sudo apt install python-pydot python-pydot-ng graphviz\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7OdmgHTp4_Ou",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c31c851b35dbc0cb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c31c851b35dbc0cb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BucSAwkHQj8Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 77ms/step - loss: 0.5771 - rmse: 0.7584\n",
      "Baseline accuracy 0.5511661767959595\n"
     ]
    }
   ],
   "source": [
    "baseline_val_loss = model.evaluate(test_dataset)[0]\n",
    "print(f\"Baseline accuracy {baseline_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ocycFbP5-X0o"
   },
   "outputs": [],
   "source": [
    "def l2_norm(vector):\n",
    "    return np.square(vector)\n",
    "\n",
    "def SDR(denoised, cleaned, eps=1e-7): # Signal to Distortion Ratio\n",
    "    a = l2_norm(denoised)\n",
    "    b = l2_norm(denoised - cleaned)\n",
    "    a_b = a / b\n",
    "    return np.mean(10 * np.log10(a_b + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcPAuMZ9SlHa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=60, restore_best_weights=True, baseline=None)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n",
    "                                                         monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch=800,\n",
    "         validation_data=test_dataset,\n",
    "         epochs=300,\n",
    "         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1ZZskDZ5L2a"
   },
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(test_dataset)[0]\n",
    "if val_loss < baseline_val_loss:\n",
    "    print(\"New model saved.\")\n",
    "    model.save('./denoiser_cnn_log_mel_generator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeJTsGxCSuhm"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLiTiK8blE0n"
   },
   "outputs": [],
   "source": [
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize:\n",
    "        div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "        audio = audio * div_fac\n",
    "    return audio, sr\n",
    "        \n",
    "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
    "    \"\"\"Adds noise to an audio sample\"\"\"\n",
    "    if len(clean_audio) >= len(noise_signal):\n",
    "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
    "        while len(clean_audio) >= len(noise_signal):\n",
    "            noise_signal = np.append(noise_signal, noise_signal)\n",
    "\n",
    "    ## Extract a noise segment from a random location in the noise file\n",
    "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
    "\n",
    "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
    "\n",
    "    speech_power = np.sum(clean_audio ** 2)\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
    "    return noisyAudio\n",
    "\n",
    "def play(audio, sample_rate):\n",
    "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uM6ajbBFlx3b"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dcnyvquSoLs"
   },
   "outputs": [],
   "source": [
    "cleanAudio, sr = read_audio(os.path.join('..','DroneBot_Audio_Files','dataset', 'clean_20.wav'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n",
    "ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(len(cleanAudio))\n",
    "adaptFactor = noise.var() / cleanAudio.var()\n",
    "noiseFactor = 20\n",
    "noiseAudio = cleanAudio + noise / adaptFactor * noiseFactor\n",
    "ipd.Audio(data=noiseAudio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaHe1okPTvV-"
   },
   "outputs": [],
   "source": [
    "noiseAudio, sr = read_audio(os.path.join('..','DroneBot_Audio_Files','dataset', 'noise_20.wav'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n",
    "ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu_eOKRfTHbp"
   },
   "outputs": [],
   "source": [
    "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "stft_features = np.abs(stft_features)\n",
    "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75M29dl3bBeF"
   },
   "outputs": [],
   "source": [
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cjO5-cjTP6t"
   },
   "outputs": [],
   "source": [
    "noiseAudioFeatureExtractor = FeatureExtractor(noiseAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "print(noisyPhase.shape)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3p5PWWkrlE3m"
   },
   "outputs": [],
   "source": [
    "predictors = prepare_input_features(noise_stft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pSoOw2fTP9N"
   },
   "outputs": [],
   "source": [
    "predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "print('predictors.shape:', predictors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5sNR4sSTP_1"
   },
   "outputs": [],
   "source": [
    "STFTFullyConvolutional = model.predict(predictors)\n",
    "print(STFTFullyConvolutional.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzCga3PdUVwG"
   },
   "outputs": [],
   "source": [
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWlUDtPzURlQ"
   },
   "outputs": [],
   "source": [
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n",
    "ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write('clean.wav', data=cleanAudio, samplerate=int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tv_7ZwWaUW0_"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)\n",
    "\n",
    "ax1.plot(cleanAudio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noiseAudio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(denoisedAudioFullyConvolutional)\n",
    "ax3.set_title(\"Denoised Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LM7E91avKA3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SpeechDenoiserCNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
